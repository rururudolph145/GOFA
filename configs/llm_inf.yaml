log_project: "ggama"
exp_name: "m_inf"
train_sample_size: -1
eval_sample_size: -1
rwpe:
task_names:
  - arxiv
llm_name: "icae"
base_llm: "mistral7blora"
llm_max_length: 4096
llm_b_size: 1
val_interval: 1
load_texts: True
mode: "nographgen"
temp: 0.1
compressed_layer: 32
max_nodes_per_hop: 5
grad_acc_step: 4
save_model:
  save: True
  steps:
  monitor: False
  time: 5
  epochs:
  top_k: -1
  last: True
load_dir:
load_model: False
last_save: False
training_precision: "bf16-mixed"
ckpt_path:
run_mode: "inf"
dec_lora: False
node_text: False

train_data_multiples: 1.0
selections: True

train_task_names:
  - arxiv
sample_size_per_task:
  - 100
hops:
  - 3

train_max_nodes_per_hops:
  - 10
ways: 5
save_suffix: "llm_instruct_ft"
instructs: False


eval_task_names:
#  - cora_node
#  - pubmed_node
#  - wikics
#  - products
#  - expla_graph
#  - fb15k237
  - scene_graph

inf_sample_size_per_task:
  - 150

inf_hops:
#  - 3
#  - 3
#  - 3
#  - 3
#  - -1
#  - 3
  - -1



inf_max_nodes_per_hops:
#  - 10
#  - 10
#  - 10
#  - 10
#  - -1
#  - 10
  - -1


inf_ways:
#  - 7
#  - 3
#  - 10
#  - 10
#  - -1
#  - 10
  - -1


inf_instructs:
#  - False
#  - False
#  - False
#  - False
#  - False
#  - False
  - False


inf_selections:
#  - True
#  - True
#  - True
#  - True
#  - True
#  - True
  - True



